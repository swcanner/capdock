{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f0377d8-fc29-4e5f-85cf-2ac65ca8f970",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#init(\" \".join(options.split('\\n')))\n",
    "\n",
    "\n",
    "import torch\n",
    "import esm\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "input_dir = \"./dataset/af2_preprocess/\"\n",
    "#os.chdir(input_dir)\n",
    "\n",
    "out_dir = \"./dataset/af2_preprocess/human/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7575e4c7-c3c4-4ab2-8672-85b9e780eaa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ce6babb-fc75-45b7-9ea8-764517f49fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46782\n"
     ]
    }
   ],
   "source": [
    "def get_fasta(file):\n",
    "    df = pd.read_csv(file,header=None,sep='%').values;\n",
    "    fa = [];\n",
    "    lab = [];\n",
    "\n",
    "    print(len(df))\n",
    "    \n",
    "    for ii in range(0,len(df),3):\n",
    "        n = df[ii][0][1:]\n",
    "        f = df[ii+1][0]\n",
    "        l = df[ii+2][0]\n",
    "        print(n,f,l)\n",
    "\n",
    "        #print(new_l)\n",
    "        fa.append( (n,f) )\n",
    "    return fa,lab\n",
    "\n",
    "def get_fasta_easy(file):\n",
    "    df = pd.read_csv(file,header=None,sep='%').values;\n",
    "    fa = [];\n",
    "\n",
    "    print(len(df))\n",
    "    \n",
    "    for ii in range(0,len(df),2):\n",
    "        n = df[ii][0][1:]\n",
    "        f = df[ii+1][0]\n",
    "        #print(n,f)\n",
    "\n",
    "        #print(new_l)\n",
    "        fa.append( (n,f) )\n",
    "    return fa\n",
    "\n",
    "def get_fasta_fancy(file):\n",
    "    df = pd.read_csv(file,header=None,sep='%').values;\n",
    "    fa = [];\n",
    "    lab = [];\n",
    "\n",
    "    #print(len(df))\n",
    "    \n",
    "    for ii in range(len(df)-2):\n",
    "        n = df[ii][0]\n",
    "        f = df[ii+1][0]\n",
    "        l = df[ii+2][0]\n",
    "        #print(n,f,l)\n",
    "        if (\">\" in n):\n",
    "            if (\">\" not in f) and (\">\" not in l):\n",
    "                #print(new_l)\n",
    "                fa.append( (n,f) )\n",
    "    return fa,lab\n",
    "\n",
    "#fa, lab = get_fasta_fancy(input_dir + 'human.fa')\n",
    "fa = get_fasta_easy(input_dir + 'human.fa')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ac5a8ee-88e0-4d42-b307-67dc9586a33b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval()\n",
    "print(\"ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4db43de5-cc6d-43e4-befb-c634d9e8e715",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23391\n",
      "8364\n"
     ]
    }
   ],
   "source": [
    "print(len(fa))\n",
    "print(len(os.listdir(out_dir)) - len(fa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aee999-c513-40e7-b722-8ed88826e1c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for ii in range(8000,len(fa)):\n",
    "    #print(ii,fa[ii][0])\n",
    "    #print(fa[ii])\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter([fa[ii]])\n",
    "    batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "\n",
    "    # Extract per-residue representations (on CPU)\n",
    "    with torch.no_grad():\n",
    "        results = model(batch_tokens, repr_layers=[33], return_contacts=True)\n",
    "    token_representations = results[\"representations\"][33]\n",
    "\n",
    "    seq_rep = []\n",
    "    for i, tokens_len in enumerate(batch_lens):\n",
    "        seq_rep.append(token_representations[i, 1 : tokens_len - 1])\n",
    "    #break;\n",
    "    #output to file\n",
    "    name = fa[ii][0]\n",
    "    np.save(out_dir + name + \"_esm.npz\",seq_rep[0].numpy())\n",
    "    #break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d41b7a70-aad0-4287-ad8f-612cd02b795d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/scanner1/Downloads/capsif2_repo/dataset'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bb9b4c-735c-47a1-84af-590cd311847e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
